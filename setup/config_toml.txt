# OpenManus Configuration File
# Copy this file to config/config.toml and add your API keys

#-----------------------------------------------------------------------------
# LANGUAGE MODEL CONFIGURATION
#-----------------------------------------------------------------------------

# Primary LLM configuration (required)
[llm]
# Model name - select based on the provider you're using
model = "gpt-4o"            # OpenAI: "gpt-4o", "gpt-4", "gpt-3.5-turbo"
                            # Anthropic: "claude-3-7-sonnet-20250219", "claude-3-opus-20240229"
                            # Ollama: "llama3", "mixtral", etc.

# API configuration
base_url = "https://api.openai.com/v1"  # OpenAI API endpoint
api_key = "YOUR_API_KEY_HERE"           # Your API key
api_type = "openai"                     # "openai", "azure", "aws", or "ollama"

# Response parameters
max_tokens = 4096           # Maximum tokens in the response
temperature = 0.0           # 0.0 = deterministic, higher = more random
max_input_tokens = null     # Maximum input tokens (null = unlimited)

# Optional: Configuration for vision capabilities
[llm.vision]
model = "gpt-4o"                        # Model for vision tasks
base_url = "https://api.openai.com/v1"  # Endpoint for vision model
api_key = "YOUR_API_KEY_HERE"           # API key for vision model (can be same as above)
temperature = 0.0

#-----------------------------------------------------------------------------
# BROWSER CONFIGURATION (Optional)
#-----------------------------------------------------------------------------

[browser]
# Whether to run browser in headless mode
headless = false
# Disable browser security features for better automation
disable_security = true
# Extra arguments to pass to the browser
extra_chromium_args = []
# Maximum content length to extract from web pages
max_content_length = 2000

# Proxy settings (if needed)
# [browser.proxy]
# server = "http://proxy-server:port"
# username = "proxy-username"
# password = "proxy-password"

#-----------------------------------------------------------------------------
# SEARCH ENGINE CONFIGURATION (Optional)
#-----------------------------------------------------------------------------

[search]
# Primary search engine to use
engine = "Google"  # "Google", "DuckDuckGo", "Baidu", "Bing"
# Fallback engines to try if primary fails
fallback_engines = ["DuckDuckGo", "Baidu"]
# Seconds to wait before retrying when all engines fail
retry_delay = 60
# Maximum number of retry attempts
max_retries = 3

#-----------------------------------------------------------------------------
# SANDBOX CONFIGURATION (Advanced)
#-----------------------------------------------------------------------------

# Uncomment to enable sandbox mode (requires Docker)
#[sandbox]
#use_sandbox = true
#image = "python:3.12-slim"
#work_dir = "/workspace"
#memory_limit = "1g"
#cpu_limit = 1.0
#timeout = 300
#network_enabled = true
